# -*- coding: utf-8 -*-
"""「Final.ipynb」的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dq_pPD0SbWnp6j09HiRZC1FtlpgTdxxk

##Dowmload the dataset
首先先下載本次作業所需要用到的資料，解壓縮後資料夾內的結構如下
```
data/
|----train_50
    |----0_0.png
    |----0_1.png
    ...
|----val_50
    |----0_450.png
    |----0_451.png
    ...
|----val_gt.csv
```
資料集是Imagenet的一小部分，是很多模型用來測試其效果的資料集，原本Imagenet有1000個分類，但這次作業只會取其中50個類別來分類，另外這次作業分為train_set和validation_set，同學需要透過train_set訓練模型，再來透過validation_set驗證圖片的第一個數字代表他所屬的class

**注意!!!
在做模型的訓練時只可以用train_set的資料，不可以用到validation_set的資料，被發現的話以零分處理**
"""

!gdown --id 1JI_LGAJADDOPfEPeOW7_3NiBYMvJ6n4J --output "data.zip"
!unzip -q "data.zip"

"""##Mount Google Drive(Optional)
由於Colab會有長期沒有使用的話自動斷線的可能性，因此可以掛載google雲端硬碟，並週期性的將模型儲存在雲端硬碟中

"""

# from google.colab import drive
# drive.mount('/content/drive')

"""##Import the package"""

import os
import glob
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch import optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import random
import tensorflow as tf

"""由於訓練過程中會有一些隨機性，為了確保每次重新訓練的情況下都可以得到同樣的結果，因此將random、torch、numpy三個套件的 random seed固定"""

import random

import torch
import numpy as np


def same_seeds(seed):
    # Python built-in random module
    random.seed(seed)
    # Numpy
    np.random.seed(seed)
    # Torch
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True

same_seeds(0)

"""##Dataset
TODO

可以參考之前提供的sample code 完成客製化的Dataset class完成客製化的Dataset class
"""

class IMAGE(Dataset):
  def __init__(self,root,transform=None):
    self.transform = transform
    self.filenames = []
    filenames = glob.glob(os.path.join(root,'*.png'))
    # print(filenames)
    for fn in filenames:
        if root == 'data/train_50':
          i = fn[14:]
          if i[1] == '_':
            i = i[:1]
          elif i[2] == '_':
            i = i[:2]
          elif i[3] == '_':
            i = i[:3]
        if root == 'data/val_50':
          i = fn[12:]
          if i[1] == '_':
            i = i[:1]
          elif i[2] == '_':
            i = i[:2]
          elif i[3] == '_':
            i = i[:3]
        i = int(i)
        self.filenames.append((fn,i))
    self.len = len(self.filenames)

  def __getitem__(self,index):
    image_fn,label = self.filenames[index]
    image = Image.open(image_fn)
    if self.transform is not None:
      image = self.transform(image)
    return image,label
  def __len__(self):
    return self.len

transform_set = [ 
  transforms.RandomResizedCrop(142, scale=(0.2, 1.0), ratio=(0.9, 1.1)), 
  transforms.RandomHorizontalFlip(),
  transforms.RandomRotation(60)
]
train_tfm = transforms.Compose([
	transforms.Resize((142, 142)),
  # transforms.RandomHorizontalFlip(),
  # transforms.RandomRotation(15),
  transforms.RandomApply(transform_set, p=0.75),
	# transforms.RandomCrop(128),
	transforms.ToTensor(),
])


test_tfm = transforms.Compose([
    transforms.Resize((142, 142)),
    transforms.CenterCrop(128),
    transforms.ToTensor(),
])

trainset = IMAGE(root='data/train_50',transform=train_tfm)
validationset = IMAGE(root='data/val_50',transform=test_tfm)

print('# images in trainset:', len(trainset)) 
print('# images in validationset:', len(validationset))

# Use the torch dataloader to iterate through the dataset
trainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)
validationset_loader = DataLoader(validationset, batch_size=1000, shuffle=False, num_workers=1)

# get some random training images
dataiter = iter(trainset_loader)
images, labels = dataiter.next()

# labels = np.asarray(labels)
# labels = tf.convert_to_tensor(labels)

print('Image tensor in each batch:', images.shape, images.dtype)
print('Label tensor in each batch:', labels.shape, labels.dtype)

import matplotlib.pyplot as plt
import numpy as np

# functions to show an image
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    
# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print('Labels:')
print(' '.join('%5s' % labels[j] for j in range(16)))

"""##MODEL
這次的作業不會一定要同學重頭開始訓練，pytorch有內建在不同種資料集訓練的模型，有各種不同的方式可以載入預訓練好的模型，以下提供一個方法給同學，但需要注意的是同學最好還是要了解一下使用的模型架構，像是以Imagenet訓練的模型最後會輸出1000個值，但是這次的小資料集只需要分成50個類別，因此可能就需要做一些調整
```
import torchvision.models as models 
model = models.vgg16(pretrained=True)
```
"""

# Use GPU if available, otherwise stick with cpu
use_cuda = torch.cuda.is_available()
torch.manual_seed(123)
device = torch.device("cuda" if use_cuda else "cpu")
print('Device used:', device)

!nvidia-smi

import torchvision.models as models 
model = models.densenet121(pretrained=True).to(device)
numFit = model.classifier.in_features
model.classifier = nn.Linear(numFit, 50).to(device)

print(model)

"""# PCA"""

# 輸出densenet121倒數第二層(denselayer15的conv2d層)
# ref:https://blog.csdn.net/Hungryof/article/details/80921417
# ref:https://zhuanlan.zhihu.com/p/362985275
activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

model.features.denseblock4.denselayer16.conv2.register_forward_hook(get_activation('features.denseblock4.denselayer15.conv2'))
x = torch.randn(64, 3, 224, 224).to(device)
output = model(x)
print(activation['features.denseblock4.denselayer15.conv2'])

# PCA降維
# ref: https://blog.csdn.net/zjh12312311/article/details/114307369

# 設置顏色 總共50個label
color = ['aliceblue','antiquewhite','aqua','aquamarine','azure','beige','bisque','black','blanchedalmond','blue',
      'blueviolet','brown','burlywood','cadetblue','chartreuse','chocolate','coral','cornflowerblue','cornsilk','crimson',
      'cyan','darkblue','darkcyan','darkgoldenrod','darkgray','darkgreen','darkkhaki','darkmagenta','darkolivegreen','darkorange',
      'darkorchid','darkred','darksalmon','darkseagreen','darkslateblue','darkslategray','darkturquoise','darkviolet','deeppink','deepskyblue',
      'dimgray','dodgerblue','firebrick','floralwhite','forestgreen','fuchsia','gainsboro','ghostwhite','gold','goldenrod']
# 繪圖
def show(v2,y):
    for i in range(len(v2)):
        plt.scatter(v2[i][0],v2[i][1],color=color[y[i]])
    plt.show()

# for (x,y) in activation['features.denseblock4.denselayer15.conv2'].cpu():
for (x,y) in trainset_loader:
    # print(y)
    x = activation['features.denseblock4.denselayer15.conv2'].cpu() #取得model輸出 [64, 3, 7, 7]
    x = x.flatten(start_dim=2,end_dim=-1) #tensor壓縮 [64, 3, 49]
    # print(x.shape)
    v2 = []
    # print(len(x))
    for i in range(len(x)):
        v2.append(torch.pca_lowrank(x[i],q=2)[1].numpy()) # 2维PCA
show(v2,y)

"""##t-SNE"""

#TSNE降維
import numpy as np
from sklearn.manifold import TSNE
x = activation['features.denseblock4.denselayer15.conv2'].cpu() #取得model輸出 [64, 3, 7, 7]
x = x.flatten(start_dim=2,end_dim=-1) #tensor壓縮 [64, 3, 49]
x = x.flatten(start_dim=1,end_dim=-1) #tensor壓縮 [64, 147]
X = np.array(x)
X_embedded = TSNE(n_components=2).fit_transform(X)
X_embedded.shape

# Commented out IPython magic to ensure Python compatibility.
#TSNE降維
# ref: https://towardsdatascience.com/t-sne-python-example-1ded9953f26
import numpy as np
from sklearn.datasets import load_digits
from scipy.spatial.distance import pdist
from sklearn.manifold.t_sne import _joint_probabilities
from scipy import linalg
from sklearn.metrics import pairwise_distances
from scipy.spatial.distance import squareform
from sklearn.manifold import TSNE
from matplotlib import pyplot as plt
import seaborn as sns
sns.set(rc={'figure.figsize':(11.7,8.27)})
palette = sns.color_palette("bright", 10)

for (X,y) in trainset_loader:
    # X = activation['features.denseblock4.denselayer15.conv2'].cpu() #取得model輸出 [64, 3, 7, 7]
    X = X.flatten(start_dim=2,end_dim=-1) #tensor壓縮 [64, 3, 49]
    X = X.flatten(start_dim=1,end_dim=-1) #tensor壓縮 [64, 147]
    # X = torch.split(X, 36)[0]
    # X, y = load_digits(return_X_y=True)

MACHINE_EPSILON = np.finfo(np.double).eps
n_components = 2
perplexity = 30

def fit(X):
    n_samples = X.shape[0]
    
    # Compute euclidean distance
    distances = pairwise_distances(X, metric='euclidean', squared=True)
    
    # Compute joint probabilities p_ij from distances.
    P = _joint_probabilities(distances=distances, desired_perplexity=perplexity, verbose=False)
    
    # The embedding is initialized with iid samples from Gaussians with standard deviation 1e-4.
    X_embedded = 1e-4 * np.random.mtrand._rand.randn(n_samples, n_components).astype(np.float32)
    
    # degrees_of_freedom = n_components - 1 comes from
    # "Learning a Parametric Embedding by Preserving Local Structure"
    # Laurens van der Maaten, 2009.
    degrees_of_freedom = max(n_components - 1, 1)
    
    return _tsne(P, degrees_of_freedom, n_samples, X_embedded=X_embedded)

def _tsne(P, degrees_of_freedom, n_samples, X_embedded):
    params = X_embedded.ravel()
    
    obj_func = _kl_divergence
    
    params = _gradient_descent(obj_func, params, [P, degrees_of_freedom, n_samples, n_components])
        
    X_embedded = params.reshape(n_samples, n_components)
    return X_embedded

def _kl_divergence(params, P, degrees_of_freedom, n_samples, n_components):
    X_embedded = params.reshape(n_samples, n_components)
    
    dist = pdist(X_embedded, "sqeuclidean")
    dist /= degrees_of_freedom
    dist += 1.
    dist **= (degrees_of_freedom + 1.0) / -2.0
    Q = np.maximum(dist / (2.0 * np.sum(dist)), MACHINE_EPSILON)
    
    # Kullback-Leibler divergence of P and Q
    kl_divergence = 2.0 * np.dot(P, np.log(np.maximum(P, MACHINE_EPSILON) / Q))
    
    # Gradient: dC/dY
    grad = np.ndarray((n_samples, n_components), dtype=params.dtype)
    PQd = squareform((P - Q) * dist)
    for i in range(n_samples):
        grad[i] = np.dot(np.ravel(PQd[i], order='K'),
                         X_embedded[i] - X_embedded)
    grad = grad.ravel()
    c = 2.0 * (degrees_of_freedom + 1.0) / degrees_of_freedom
    grad *= c
    return kl_divergence, grad

def _gradient_descent(obj_func, p0, args, it=0, n_iter=400,
                      n_iter_check=1, n_iter_without_progress=1000,
                      momentum=0.8, learning_rate=200.0, min_gain=0.01,
                      min_grad_norm=1e-7):
    
    p = p0.copy().ravel()
    update = np.zeros_like(p)
    gains = np.ones_like(p)
    error = np.finfo(np.float).max
    best_error = np.finfo(np.float).max
    best_iter = i = it
    
    for i in range(it, n_iter):
        error, grad = obj_func(p, *args)
        grad_norm = linalg.norm(grad)
        inc = update * grad < 0.0
        dec = np.invert(inc)
        gains[inc] += 0.2
        gains[dec] *= 0.8
        np.clip(gains, min_gain, np.inf, out=gains)
        grad *= gains
        update = momentum * update - learning_rate * grad
        p += update
        print("[t-SNE] Iteration %d: error = %.7f,"
                      " gradient norm = %.7f"
#                       % (i + 1, error, grad_norm))
        
        if error < best_error:
                best_error = error
                best_iter = i
        elif i - best_iter > n_iter_without_progress:
            break
        
        if grad_norm <= min_grad_norm:
            break
    return p

X_embedded = fit(X)
sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full')

"""##Training function"""

def save_checkpoint(checkpoint_path, model, optimizer):
    state = {'state_dict': model.state_dict(),
             'optimizer' : optimizer.state_dict()}
    torch.save(state, checkpoint_path)
    print('model saved to %s' % checkpoint_path)
    
def load_checkpoint(checkpoint_path, model, optimizer):
    state = torch.load(checkpoint_path)
    model.load_state_dict(state['state_dict'])
    optimizer.load_state_dict(state['optimizer'])
    print('model loaded from %s' % checkpoint_path)

def train_save(model, epoch, save_interval, log_interval=100):
    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)
    criterion = nn.CrossEntropyLoss()
    model.train()
    
    iteration = 0
    for ep in range(epoch):
        model.train()
        for batch_idx, (data, target) in enumerate(trainset_loader):
            data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            
            if iteration % log_interval == 0:
                print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                    ep, batch_idx * len(data), len(trainset_loader.dataset),
                    100. * batch_idx / len(trainset_loader), loss.item()))
            if iteration % save_interval == 0 and iteration > 0:
                save_checkpoint('model%i.pth' % iteration, model, optimizer)
            iteration += 1
        validate(model)
    save_checkpoint('model%i.pth' % iteration, model, optimizer)

"""##Validation"""

def validate(model):
    criterion = nn.CrossEntropyLoss()
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in validationset_loader:
            data, target = data.cuda(), target.cuda()
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(validationset_loader.dataset)
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(validationset_loader.dataset),
        100. * correct / len(validationset_loader.dataset)))

"""##Start Training"""

# Start training the model
train_save(model,10,500,100)

"""##Load Model"""

optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)

# load from the final checkpoint
load_checkpoint('model3520.pth', model, optimizer)

"""##Prediction"""

# Some modules like Dropout or BatchNorm affect if the model is in training mode.
model.eval()

# Initialize a list to store the filename from validaiton set.
filename_list = []
path = 'data/val_50'
for infile in glob.glob(os.path.join(path, '*.png')):
  filename_list.append(infile[12:])

# Initialize a list to store the predictions.
predictions = []
# Iterate the validation set by batches.
for batch in validationset_loader:
    # A batch consists of image data and corresponding labels.
    # But here the variable "labels" is useless since we do not have the ground-truth.
    # If printing out the labels, you will find that it is always 0.
    # This is because the wrapper (DatasetFolder) returns images and labels for each batch,
    # so we have to create fake labels to make it work normally.
    imgs, labels = batch

    # We don't need gradient in testing, and we don't even have labels to compute loss.
    # Using torch.no_grad() accelerates the forward process.
    with torch.no_grad():
        logits = model(imgs.to(device))

    # Take the class with greatest logit as prediction and record it.
    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())

# Save predictions into the file.
with open("test_pred.csv", "w") as f:

    # The first row must be "image_id, label"
    f.write("image_id,label\n")

    # For the rest of the rows, each image corresponds to a predicted class.
    for i, pred in  enumerate(predictions):
         f.write(f"{filename_list[i]},{pred}\n")